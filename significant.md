# Statistical Significance and the Replication Crisis

Most scientific publications are wrong. In 2005, Ioannidis published a
[famous paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/)
which demonstrated why. To simplify dramatically, we use a confidence
interval of 5%. If people run 100 experiments, we will see 5 falsely
statistically significant results. These results will be
published. Since the majority of studies have no effect, published
results are dominated by statistical glitches. Several [popular
publications](http://bigthink.com/neurobonkers/believe-it-or-not-most-published-research-findings-are-probably-false)
explain this in a way more intuitive (if less rigorous) than the
original Ioannidis paper.

This result does not even take into account experimental errors,
analysis errors, or 

These effects lead to the [replication
crisis](https://en.wikipedia.org/wiki/Replication_crisis). Most
studies, especially in fields like medicine and social science, cannot
be replicated. By a conservative estimate,
[50-65%](http://www.nature.com/nrd/journal/v10/n9/full/nrd3545.html)
of medical results do not replicate, and by a more liberal one
[88%](http://www.reuters.com/article/us-science-cancer-idUSBRE82R12P20120328)
do not.

These effects also lead to high publication counts. Looking at a
scientific result from multiple angles, and validating results, takes
time.